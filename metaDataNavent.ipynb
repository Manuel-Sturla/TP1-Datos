{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <strong style=\"font-size:40px\"> Walkthrough - Valuación de inmuebles en un sistema de búsqueda online - ECI 2018 - Navent </strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Creen la carpeta data/ y pongan ahí los archivos `train.csv` y `test.csv` para que la notebook funcione!</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda:\n",
    "* Análisis exploratorio básico\n",
    "* Presentación de tres modelos súper simples.\n",
    "* Código para hacer un submit real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis exploratorio\n",
    "\n",
    "El dataset son propiedades en `venta` en México entre `2012` y `2016`, valuadas en `pesos mexicanos`. El csv de train tiene `240K` filas y `22` columnas. El csv de test tiene `60K` filas (y 21 columnas). La columna a predecir es `precio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerías de análisis de datos\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "pd.set_option('mode.chained_assignment', None) # Deshabilita SettingWithCopyWarning. Ojo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el dataframe\n",
    "df = pd.read_csv('data/train.csv', index_col='id', parse_dates=['fecha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columnas: {df.columns}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Columnas de texto | Tipo | Comentarios | \n",
    "|:-|:-|:- | \n",
    "|`titulo`| Texto | El título de la propiedad publicada |\n",
    "|`descripcion`| Texto | La descripción de la propieadad publicada |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Localización | Tipo | Comentarios | \n",
    "|:-|:-|:- | \n",
    "|`direccion` | String | La dirección (calle y número) de la propiedad |\n",
    "|`ciudad`| String |  La ciudad de la propiedad |\n",
    "|`idzona`| Int |  Una zona es una parte de un ciudad |\n",
    "|`provincia`| String  | La provincia donde está localizada la propiedad|\n",
    "|`lat`| Float | Latitud |\n",
    "|`lng`| Float | Longitud|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Cualidad | Tipo | Comentarios | \n",
    "|:-|:-|:- | \n",
    "| `tipodepropiedad` | Categórico (String) | Casa, apartamento, terreno, etc|\n",
    "| `metrostotales` | Int | Metros totales de la propiedad | \n",
    "| `metroscubiertos` | Int | Metros cubiertos de la propiedad |\n",
    "| `antiguedad` | Int | Antigüedad de la propiedad |\n",
    "| `habitaciones` | Int | Cantidad de habitaciones |\n",
    "| `garages` | Int | Cantidad de garages |\n",
    "| `banos` | Int | Cantidad de baños|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Fecha/Amenities/Otros | Tipo | Comentarios | \n",
    "|:-|:-|:- | \n",
    "| `fecha` | Date | Fecha de publicación |\n",
    "| `gimnasio` |  Bool | Si el edificio o la propiedad tiene un gimnasio |\n",
    "| `usosmultiples` |  Bool |Si el edificio o la propiedad tiene un SUM |\n",
    "| `piscina` |  Bool | Si el edificio o la propiedad tiene un piscina |\n",
    "| `escuelascercanas` |  Bool |Si la propiedad tiene escuelas cerca |\n",
    "| `centroscomercialescercanos` | Bool | Si la propiedad tiene centros comerciales cerca |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable dependiente | Tipo | Comentarios | \n",
    "|:-|:-|:- | \n",
    "| `precio` | Float | Valor de publicación de la propiedad en pesos mexicanos |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset está tomado directamente de la página y tiene muchos datos faltantes o mal cargados. Lo curamos un poco, pero sigue teniendo mucho ruido. Por ejemplo, latitud y longitud solo están presentes en el 48% de los datos, dirección y metros totales faltan para el ~20%, etc. Además de los nulls, pueden encontrar cosas sin sentido que responden a cargas negligentes de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nulls = pd.DataFrame(df.isnull().sum().sort_values(), columns=['nulls'])\n",
    "nulls['porcentaje'] = round(100*nulls['nulls'] / len(df), 2)\n",
    "nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El precio tiene una distribución asimétrica positiva (a izquierda) con long-tail. A modo heurístico, la tasa USD2MXN hoy es de ~20. O sea que 2.000.000 MXN serían 100.000 USD y 12.000.000 MXN, 600.000 USD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "axes[0].ticklabel_format(style = 'plain')\n",
    "df['precio'].hist(bins=80, ax=axes[0], color='r'); \n",
    "#np.log(df['precio']).hist(bins=80, ax=axes[0], color='g'); \n",
    "df['precio'].plot(kind='box', ax=axes[1]);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de propiedad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tipos de propiedad y precio promedio por tipo de propiedad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total tipos de propiedad: {df.tipodepropiedad.nunique()}\")\n",
    "df.tipodepropiedad.value_counts().plot(kind='bar', figsize=(15, 5), rot=70, \n",
    "                                       title=\"Cantidad de propiedades por tipo de propiedad\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precio promedio por tipo de propiedad\n",
    "#df.groupby('tipodepropiedad').agg({'precio': 'mean'})\\\n",
    "#    .sort_values('precio', ascending=False)\\\n",
    "#    .plot(kind='bar', figsize=(15, 5), rot=70, title=\"Precio promedio por tipo de propiedad\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provincias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total de provincias: {df.provincia.nunique()}\")\n",
    "df.provincia.value_counts().plot(kind='bar', figsize=(15, 5), rot=70, title=\"Propiedades por provincia\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precio por provincia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('provincia').agg({'precio': 'mean'})\\\n",
    "    .sort_values('precio', ascending=False)\\\n",
    "    .plot(kind='bar', figsize=(15, 5), rot=70, title=\"Precio promedio por provincia\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total de ciudades: {df.ciudad.nunique()}\")\n",
    "df.ciudad.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dos variables se correlacionan positivamente si cuando una crece, la otra crece también y se correlacionan negativamente si cuando una crece, la otra decrece. En realidad, la relación es más débil: se correlacionan si, al aumentar una, la otra *tiende* a aumentar, en general. \n",
    "\n",
    "Como ahora vamos a ver, el precio y los metros cubiertos se correlacionan positivamente (lo que significa que las propiedades más grandes tienden a ser más caras que las más chicas...)\n",
    "\n",
    "\n",
    "*NB: Correlación no implica causalidad*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrego dos columnas calculadas a partir de la fecha (timestamp y 201602,...)\n",
    "df['ts'] = df.fecha.astype(int)\n",
    "df['anio_mes'] = df['fecha'].map(lambda x: 100 * x.year + x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlaciones como heatmap\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(df.corr(), square=True, annot=True, fmt='.2f');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inflación mexicana\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.boxplot(x=df.fecha.dt.year, y='precio', data=df, palette='Blues')\n",
    "plt.title(\"Aumento de precios por año\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlacion entre precio y metros cubiertos: descripción gráfica\n",
    "column = 'metroscubiertos'\n",
    "\n",
    "# Scatter plot\n",
    "df_sample = df.sample(frac=0.05).copy().dropna().sort_values(column)\n",
    "df_sample.plot.scatter(x=column, y='precio', figsize=(15, 5), title=\"Correlación entre metros cubiertos y precio\")\n",
    "plt.ticklabel_format(style = 'plain')\n",
    "\n",
    "# Best-fit lineal\n",
    "x = df_sample[column]\n",
    "y = df_sample['precio']\n",
    "f = np.poly1d(np.polyfit(x, y, deg=1))  \n",
    "plt.plot(x.unique(), f(x.unique()), c='r', linewidth=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución de metros cubiertos\n",
    "# _, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "# plt.ticklabel_format(style = 'plain')\n",
    "# df[column].hist(bins=40, ax=axes[0], color='orange');\n",
    "# df[column].plot(kind='box', ax=axes[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos utilidades y modelos de sklearn\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métrica: Root Mean Squared Logarithmic Error\n",
    "$\n",
    "\\huge\n",
    "\\begin{align}\n",
    "RMSLE = \\sqrt{\\frac{\\sum((log(\\text{actual}+1) - log(\\text{pred}+1))^2}{n}}\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métrica de evaluación\n",
    "def RMSLE(actual, pred):\n",
    "    return (np.mean((np.log(actual + 1) - np.log(pred + 1)) ** 2)) **.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intuición detrás de RMSLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La razón para usar error logarítmico es que relativiza el error al valor absoluto considerado. Por ejemplo, consideremos un error absoluto de 1000 sobre un valor absoluto de 10 y uno de 100.000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_1 = 10\n",
    "actual_2 = 1000000\n",
    "error = 1000\n",
    "\n",
    "abs_error_1 = np.abs(actual_1 - (actual_1 + error))\n",
    "abs_error_2 = np.abs(actual_2 - (actual_2 + error))\n",
    "\n",
    "log_error_1 = np.abs(np.log(actual_1 + 1) - np.log(actual_1 + error + 1))\n",
    "log_error_2 = np.abs(np.log(actual_2 + 1) - np.log(actual_2 + error + 1))\n",
    "\n",
    "print(f\"Error relativo grande - Abs: {abs_error_1:.4f}, Log:{log_error_1:.4f}\")\n",
    "print(f\"Error relativo chico  - Abs: {abs_error_2:.4f}, Log:{log_error_2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1: [DummyRegressor](http://scikit-learn.org/stable/modules/model_evaluation.html#dummy-estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un DummyRegressor(strategy='mean') predice el precio promedio del train set (como constante), no es verdaderamente útil, pero sirve como baseline para darse una idea del bottom-line de valores de predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiramos todas las columnas no numéricas para que sklearn nos acepte el dataframe. \n",
    "# Igualmente, el DummyRegressor no va a utilizar ninguna más que el precio \n",
    "drop_cols = ['fecha', 'ciudad', 'idzona', 'tipodepropiedad', 'provincia', 'titulo', 'descripcion', 'direccion']\n",
    "X = df.drop(['precio'] + drop_cols, axis=1)\n",
    "y = df['precio']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "print(f\"Train shapes: X={X_train.shape} y={y_train.shape}\")\n",
    "print(f\"Test  shapes: X={X_test.shape}  y={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyRegressor(strategy='mean').fit(X_train, y_train)\n",
    "pred = dummy.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Promedio de precios del train set: {y_train.mean()}\")\n",
    "print(f\"Primeras 3 predicciones: {pred[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_rmsle = RMSLE(y_test, pred)\n",
    "dummy_rmsle_train = RMSLE(y_train, dummy.predict(X_train))\n",
    "print(f\"RMSLE DummyRegressor (train): {dummy_rmsle_train:.5f}\")\n",
    "print(f\"RMSLE DummyRegressor: {dummy_rmsle:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSLE no tiene cota superior, asi que 0.903 no es tan malo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsle_1 = RMSLE(y_test, np.array([1 for _ in range(len(y_test))]))\n",
    "rmsle_inf = RMSLE(y_test, np.array([9999999999999999999 for _ in range(len(y_test))]))\n",
    "print(f\"Si predijesemos todo 1 el RMSLE sería: {rmsle_1:.4f}\")\n",
    "print(f\"Si predijesemos un valor altísimo, sería: {rmsle_inf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 2: Regresión lineal sobre metros cubiertos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['metroscubiertos']]\n",
    "y = df['precio']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "print(f\"Train shapes: X={X_train.shape} y={y_train.shape}\")\n",
    "print(f\"Test  shapes: X={X_test.shape}  y={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputación de nulls\n",
    "Un [Imputer](http://scikit-learn.org/stable/modules/preprocessing.html#imputation) (\"imputador\") es una manera de rellenar los nulls  un poco más sofisticada que reemplazarlos por 0 o por -1 (o tirarlos).\n",
    "\n",
    "En este caso, reemplazamos los nulls por el valor promedio de las muestras existentes, pero podríamos reemplazarlos por otro valor (la moda, la mediana, etc).\n",
    "\n",
    "Acá imputamos los metros cubiertos.\n",
    "\n",
    "**OJO!** Al tomar el promedio (`fittear`) hay que hacerlo sobre el train set, sino estaríamos leakeando información!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = Imputer()\n",
    "X_train['metroscubiertos'] = imp.fit_transform(X_train[['metroscubiertos']])\n",
    "X_test['metroscubiertos'] = imp.transform(X_test[['metroscubiertos']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = LinearRegression().fit(X_train, y_train)\n",
    "pred = linear_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El modelo de regresion lineal con una variable obtiene RMSLE=0.65\n",
    "linear_rmsle_train = RMSLE(y_train, linear_model.predict(X_train))\n",
    "linear_rmsle = RMSLE(y_test, pred)\n",
    "print(f\"RMSLE LinearRegression (train): {linear_rmsle_train:.5f}\")\n",
    "print(f\"RMSLE LinearRegression: {linear_rmsle:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 3: Árbol de decisión sobre varios features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droppeamos strings y columnas complejas y repetidas\n",
    "drop_cols = ['titulo', 'descripcion', 'direccion', 'lat', 'lng', 'fecha', 'ts', 'idzona']\n",
    "df2 = df.drop(drop_cols, axis=1).copy()\n",
    "print(f\"Columnas ({len(df2.columns)}): {df2.columns.tolist()}\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observamos nulls y de features categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df2.isnull().sum())\n",
    "numeric_columns_with_nulls = list(set(df2.columns[df2.isnull().sum() > 0].tolist()) \\\n",
    "                                  - set(['tipodepropiedad', 'ciudad', 'provincia']))\n",
    "print(numeric_columns_with_nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot-encodeamos los categóricos [`tipodepropiedad`, `ciudad` y `provincia`] sobre todo el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con dummy_na=True, creamos la categoria \"Es nulo\" como una coordenada más de los one-hot vectors\n",
    "# Comentar: ¿Hay leaks acá? ¿Sí / No? ¿Por qué?\n",
    "df2 = pd.get_dummies(df2, dummy_na=True)\n",
    "print(f\"Cantidad de columnas después del one-hot-encoding: {len(df2.columns)}\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ejemplo de one-hot-encoding (pasar categóricos a `dummies`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoding_example_df = pd.DataFrame(['red', 'red', 'green', 'blue', np.nan], columns=['color'])\n",
    "display(one_hot_encoding_example_df)\n",
    "display(pd.get_dummies(one_hot_encoding_example_df))\n",
    "display(pd.get_dummies(one_hot_encoding_example_df, dummy_na=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más sobre one-hot-encoding [acá](https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputación de nulls numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para los nulls numéricos, usar un Imputer con strategy mean (reemplazamos los NaN por el promedio)\n",
    "# Para no leakear, spliteamos el dataset antes\n",
    "X2 = df2.drop(\"precio\", axis=1)\n",
    "y2 = df2['precio']\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in numeric_columns_with_nulls:\n",
    "    imp = Imputer()\n",
    "    X2_train[c] = imp.fit_transform(X2_train[[c]])\n",
    "    X2_test[c] = imp.transform(X2_test[[c]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor().fit(X2_train, y2_train)\n",
    "tree_pred = tree.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_rmsle = RMSLE(y2_test, tree_pred)\n",
    "tree_rmsle_train = RMSLE(y2_train, tree.predict(X2_train))\n",
    "print(f\"RMSLE DecisionTreeRegressor (train): {tree_rmsle_train:.5f}\")\n",
    "print(f\"RMSLE DecisionTreeRegressor: {tree_rmsle:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSLE DummyRegressor       : {dummy_rmsle:.5f}\")\n",
    "print(f\"RMSLE LinearRegressor      : {linear_rmsle:.5f}\")\n",
    "print(f\"RMSLE DecisionTreeRegressor: {tree_rmsle:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearRegressor para submit\n",
    "El mismo proceso pero con el archivo test.csv en lugar de haciendo train/test split para que tengan el código disponible para generar un submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/train.csv\", index_col=0)\n",
    "df_submit = pd.read_csv(\"data/test.csv\", index_col=0)\n",
    "\n",
    "# Imputamos los NaNs\n",
    "imp = Imputer()\n",
    "df_train['metroscubiertos'] = imp.fit_transform(df_train[['metroscubiertos']])\n",
    "df_submit['metroscubiertos'] = imp.transform(df_submit[['metroscubiertos']])\n",
    "\n",
    "linear_pred = LinearRegression()\\\n",
    "                    .fit(df_train[['metroscubiertos']], df_train['precio'])\\\n",
    "                    .predict(df_submit[['metroscubiertos']])\n",
    "\n",
    "res = pd.DataFrame(linear_pred, index=df_submit.index, columns=['precio'])\n",
    "display(res.head())\n",
    "res.to_csv(\"data/workshop-submission-linear.csv\", header=False) # RMSLE=0.65487"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eso es todo. ¡Suerte en la competencia!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links relevantes\n",
    "\n",
    "* [Competencia](https://metadata.fundacionsadosky.org.ar/competition/4/)\n",
    "* Consultas: [eci2018@navent.com](mailto:eci2018@navent.com)\n",
    "\n",
    "\n",
    "## Referencias\n",
    "* [Diferencia entre RMSE y RMSLE (quora)](https://www.quora.com/What-is-the-difference-between-an-RMSE-and-RMSLE-logarithmic-error-and-does-a-high-RMSE-imply-low-RMSLE)\n",
    "* [Imputer (sklearn user guide)](http://scikit-learn.org/stable/modules/preprocessing.html#imputation)\n",
    "* [DummyRegressor (sklearn user guide)](http://scikit-learn.org/stable/modules/model_evaluation.html#dummy-estimators)\n",
    "* [One-hot-encoding (kernel en Kaggle)](https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding)\n",
    "* [Seaborn](https://seaborn.pydata.org/introduction.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
